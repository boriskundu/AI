{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8ced4e",
   "metadata": {},
   "source": [
    "### Author: Boris Kundu (kunduboris@gmail.com, 470-746-3137) ###\n",
    "\n",
    "### Problem Statement ###\n",
    "Apply common Machine Learning techniques on relevant sections \n",
    "(chief complaint, history of present illness, and discharge diagnosis) \n",
    "of clinical data (clinical_notes\\training_data\\*.txt) to uncover \n",
    "common underlying factors for a given medical condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714d990",
   "metadata": {},
   "source": [
    "### 1. Setup libraries ###\n",
    "1. Install packages\n",
    "2. Import packages\n",
    "3. Download other libraries (as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "577bdc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "\n",
    "#!pip install --upgrade pip\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "\n",
    "#!pip install nltk\n",
    "\n",
    "#!pip install spacy\n",
    "\n",
    "#!pip install sklearn\n",
    "#!pip install pyLDAvis\n",
    "\n",
    "# Import packages\n",
    "\n",
    "import os\n",
    "import string\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12daf6f9",
   "metadata": {},
   "source": [
    "### 2. Data loading ###\n",
    "1. Define relevant sections\n",
    "2. Parse given text files\n",
    "3. Create raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2c6b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sections\n",
    "relevant_sections = {\n",
    "                    'complaint': ('chief complaint:','major surgical or invasive procedure:'),\n",
    "                    'history': ('history of present illness:','past medical history:'),\n",
    "                    'diagnosis': ('discharge diagnosis:','discharge condition:')\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21ee1854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from directory\n",
    "def read_clinical_notes(data_directory):\n",
    "    if data_directory[-1] != '/':\n",
    "        data_directory += '/'\n",
    "    all_files = os.listdir(data_directory)\n",
    "    text_files = [fn for fn in all_files if fn[-4:] == '.txt']\n",
    "    clinical_records = {}\n",
    "    for file in text_files:\n",
    "        with open (data_directory+file,'rt') as curr_file:\n",
    "            clinical_records[file[:len(file)-4]] = curr_file.read().lower()\n",
    "    print(f'Total clinical records found: {len(text_files)}')\n",
    "    return clinical_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c75bafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crate raw dataset\n",
    "def create_raw_dataset(records, relevant_sections):\n",
    "    record_list = []\n",
    "    for k, v in records.items():\n",
    "        rec = {}\n",
    "        rec['id'] = int(k)\n",
    "        for section, (prefix,suffix) in relevant_sections.items():\n",
    "            rec[section] = v[v.find(prefix)+len(prefix):v.find(suffix)]\n",
    "        record_list.append(rec)\n",
    "    return pd.DataFrame(record_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66142e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clinical records found: 303\n"
     ]
    }
   ],
   "source": [
    "# Get all clinical records\n",
    "records = read_clinical_notes('training_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "616a2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data frame from raw dataset\n",
    "raw = create_raw_dataset(records,relevant_sections)\n",
    "raw['underlying_factors'] = raw['complaint'] + ' ' + raw['history'] + ' ' + raw['diagnosis']\n",
    "# Drop separate sections\n",
    "raw.drop(['history', 'diagnosis'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3509cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>complaint</th>\n",
       "      <th>underlying_factors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100035</td>\n",
       "      <td>\\npost-cardiac arrest, asthma exacerbation\\n\\n</td>\n",
       "      <td>\\npost-cardiac arrest, asthma exacerbation\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100039</td>\n",
       "      <td>\\nabdominal pain\\n\\n</td>\n",
       "      <td>\\nabdominal pain\\n\\n \\n38 yo f w/ h/o all in r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100187</td>\n",
       "      <td>\\nsob\\n\\n</td>\n",
       "      <td>\\nsob\\n\\n \\n64 yo woman w/ h/o recurrent pes s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100229</td>\n",
       "      <td>\\nhypotension with elevated lactate, code seps...</td>\n",
       "      <td>\\nhypotension with elevated lactate, code seps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100564</td>\n",
       "      <td>\\nsvc thrombosis\\n\\n</td>\n",
       "      <td>\\nsvc thrombosis\\n\\n \\n43 yo male with hx of r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                          complaint  \\\n",
       "0  100035     \\npost-cardiac arrest, asthma exacerbation\\n\\n   \n",
       "1  100039                               \\nabdominal pain\\n\\n   \n",
       "2  100187                                          \\nsob\\n\\n   \n",
       "3  100229  \\nhypotension with elevated lactate, code seps...   \n",
       "4  100564                               \\nsvc thrombosis\\n\\n   \n",
       "\n",
       "                                  underlying_factors  \n",
       "0  \\npost-cardiac arrest, asthma exacerbation\\n\\n...  \n",
       "1  \\nabdominal pain\\n\\n \\n38 yo f w/ h/o all in r...  \n",
       "2  \\nsob\\n\\n \\n64 yo woman w/ h/o recurrent pes s...  \n",
       "3  \\nhypotension with elevated lactate, code seps...  \n",
       "4  \\nsvc thrombosis\\n\\n \\n43 yo male with hx of r...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check raw data \n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f9ed976",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  303 non-null    int64 \n",
      " 1   complaint           303 non-null    object\n",
      " 2   underlying_factors  303 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check info\n",
    "raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab12423",
   "metadata": {},
   "source": [
    "### 3. Data pre-processing ###\n",
    "\n",
    "1. Clean data (punctuations, white spaces etc.)\n",
    "2. Tokenize text\n",
    "3. Remove stopwords\n",
    "4. Lemmatize text\n",
    "5. Filter unwanted Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e77ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus specific stop words\n",
    "custom_stop_words = ['history','date','birth','sex','patient','hospital', 'po' ,'mg', 'yo', 'year', 'male', 'female','hp','bp','rr']\n",
    "# POS filtering NOUN, VERB, ADJECTIVE, PROVERB\n",
    "allowed_tags = ['NN','NNP','NNPS','NNS',\n",
    "                'VB','VBD','VBG','VBN','VBP','VBZ',\n",
    "                'JJ','JJR', 'JJS', \n",
    "                'RB', 'RBR', 'RBS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98a19e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes punctuations\n",
    "def remove_punctuation(text):\n",
    "    for punc in string.punctuation:\n",
    "        text = text.replace(punc, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d83fcdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "def clean(dataset):\n",
    "    sections = [col for col in dataset.columns if dataset[col].dtype == object]\n",
    "    # Replace any text between [] including []\n",
    "    dataset = dataset.replace(r'[\\[].*?[\\]]', ' ', regex = True)\n",
    "    for sec in sections:\n",
    "        # Remove new line chaarcters '\\n'\n",
    "        dataset[sec] = dataset[sec].str.replace('\\n',' ')\n",
    "        # Remove punctuations\n",
    "        dataset[sec] = dataset[sec].apply(remove_punctuation)\n",
    "        # Remove numbers\n",
    "        dataset[sec] = dataset[sec].str.replace(r'\\d+', ' ', regex = True)\n",
    "        # Remove single characters\n",
    "        dataset[sec] = dataset[sec].str.replace(r'\\b\\w\\b', ' ', regex = True)\n",
    "        # Remove sequence of white spaces\n",
    "        dataset[sec] = dataset[sec].str.replace(r'\\s+', ' ', regex = True)\n",
    "        # Remove any leading or trailing white spaces\n",
    "        dataset[sec] = dataset[sec].str.strip()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd3efe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all stop words\n",
    "def get_stop_words(custom_stop_words):\n",
    "    stop_words = STOP_WORDS.union(set(stopwords.words('english')))\n",
    "    stop_words = stop_words.union(set(custom_stop_words))\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba561427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doc/sentence from tokens/words/lemmas\n",
    "def word2doc(words):\n",
    "    text_out = ' '.join(words)\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ab85c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "def tokenize_text(text):\n",
    "    stop_words = get_stop_words(custom_stop_words)\n",
    "    tokens = [token for token in nltk.tokenize.word_tokenize(text) if token not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdfd6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter words that are not NOUN, VERB, ADJECTIVE, PROVERB\n",
    "def lemmatize_pos_filtering(words):\n",
    "    stop_words = get_stop_words(custom_stop_words)\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    filtered_words = []\n",
    "    for word in words:\n",
    "        tag = nltk.pos_tag([word])[0][1]\n",
    "        if tag in allowed_tags:\n",
    "            tag = tag[0].lower()\n",
    "            if tag == 'j':\n",
    "                tag = 'a'\n",
    "            else:\n",
    "                tag = tag if tag in ['r', 'n', 'v'] else None\n",
    "            if not tag:\n",
    "                lemma = word\n",
    "            else:\n",
    "                lemma = wordnet_lemmatizer.lemmatize(word, tag)\n",
    "            if lemma not in stop_words:\n",
    "                filtered_words.append(lemma)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a33dff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "def prepare_data(df, input_feature, out_feature):\n",
    "    # Get tokens\n",
    "    df[out_feature + '_Tokens'] = df[input_feature].apply(tokenize_text)\n",
    "    # Get POS filtered words\n",
    "    df[out_feature + '_Lemmas'] = df[out_feature + '_Tokens'].apply(lemmatize_pos_filtering)\n",
    "    # Get POS filtered text\n",
    "    df[out_feature] = df[out_feature + '_Lemmas'].apply(word2doc)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf9d94be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean textual data\n",
    "df = clean(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f03bd561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "complaint             0\n",
       "underlying_factors    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0856aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare underlying factors\n",
    "df = prepare_data(df, 'underlying_factors', 'prepared_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f1823d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>100035</td>\n",
       "      <td>100039</td>\n",
       "      <td>100187</td>\n",
       "      <td>100229</td>\n",
       "      <td>100564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complaint</th>\n",
       "      <td>post cardiac arrest asthma exacerbation</td>\n",
       "      <td>abdominal pain</td>\n",
       "      <td>sob</td>\n",
       "      <td>hypotension with elevated lactate code sepsis</td>\n",
       "      <td>svc thrombosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>underlying_factors</th>\n",
       "      <td>post cardiac arrest asthma exacerbation mr is ...</td>\n",
       "      <td>abdominal pain yo all in remission cord transp...</td>\n",
       "      <td>sob yo woman recurrent pes filter gib while an...</td>\n",
       "      <td>hypotension with elevated lactate code sepsis ...</td>\n",
       "      <td>svc thrombosis yo male with hx of rectal ca dm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared_corpus_Tokens</th>\n",
       "      <td>[post, cardiac, arrest, asthma, exacerbation, ...</td>\n",
       "      <td>[abdominal, pain, remission, cord, transplant,...</td>\n",
       "      <td>[sob, woman, recurrent, pes, filter, gib, anti...</td>\n",
       "      <td>[hypotension, elevated, lactate, code, sepsis,...</td>\n",
       "      <td>[svc, thrombosis, hx, rectal, dmii, histoplasm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared_corpus_Lemmas</th>\n",
       "      <td>[post, cardiac, arrest, asthma, exacerbation, ...</td>\n",
       "      <td>[abdominal, pain, remission, cord, transplant,...</td>\n",
       "      <td>[sob, woman, recurrent, pe, filter, gib, antic...</td>\n",
       "      <td>[hypotension, elevate, lactate, code, sepsis, ...</td>\n",
       "      <td>[svc, thrombosis, hx, rectal, dmii, histoplasm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared_corpus</th>\n",
       "      <td>post cardiac arrest asthma exacerbation mr old...</td>\n",
       "      <td>abdominal pain remission cord transplant anthr...</td>\n",
       "      <td>sob woman recurrent pe filter gib anticoagulat...</td>\n",
       "      <td>hypotension elevate lactate code sepsis yom pm...</td>\n",
       "      <td>svc thrombosis hx rectal dmii histoplasmosis p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        0  \\\n",
       "id                                                                 100035   \n",
       "complaint                         post cardiac arrest asthma exacerbation   \n",
       "underlying_factors      post cardiac arrest asthma exacerbation mr is ...   \n",
       "prepared_corpus_Tokens  [post, cardiac, arrest, asthma, exacerbation, ...   \n",
       "prepared_corpus_Lemmas  [post, cardiac, arrest, asthma, exacerbation, ...   \n",
       "prepared_corpus         post cardiac arrest asthma exacerbation mr old...   \n",
       "\n",
       "                                                                        1  \\\n",
       "id                                                                 100039   \n",
       "complaint                                                  abdominal pain   \n",
       "underlying_factors      abdominal pain yo all in remission cord transp...   \n",
       "prepared_corpus_Tokens  [abdominal, pain, remission, cord, transplant,...   \n",
       "prepared_corpus_Lemmas  [abdominal, pain, remission, cord, transplant,...   \n",
       "prepared_corpus         abdominal pain remission cord transplant anthr...   \n",
       "\n",
       "                                                                        2  \\\n",
       "id                                                                 100187   \n",
       "complaint                                                             sob   \n",
       "underlying_factors      sob yo woman recurrent pes filter gib while an...   \n",
       "prepared_corpus_Tokens  [sob, woman, recurrent, pes, filter, gib, anti...   \n",
       "prepared_corpus_Lemmas  [sob, woman, recurrent, pe, filter, gib, antic...   \n",
       "prepared_corpus         sob woman recurrent pe filter gib anticoagulat...   \n",
       "\n",
       "                                                                        3  \\\n",
       "id                                                                 100229   \n",
       "complaint                   hypotension with elevated lactate code sepsis   \n",
       "underlying_factors      hypotension with elevated lactate code sepsis ...   \n",
       "prepared_corpus_Tokens  [hypotension, elevated, lactate, code, sepsis,...   \n",
       "prepared_corpus_Lemmas  [hypotension, elevate, lactate, code, sepsis, ...   \n",
       "prepared_corpus         hypotension elevate lactate code sepsis yom pm...   \n",
       "\n",
       "                                                                        4  \n",
       "id                                                                 100564  \n",
       "complaint                                                  svc thrombosis  \n",
       "underlying_factors      svc thrombosis yo male with hx of rectal ca dm...  \n",
       "prepared_corpus_Tokens  [svc, thrombosis, hx, rectal, dmii, histoplasm...  \n",
       "prepared_corpus_Lemmas  [svc, thrombosis, hx, rectal, dmii, histoplasm...  \n",
       "prepared_corpus         svc thrombosis hx rectal dmii histoplasmosis p...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check head\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b536e5a",
   "metadata": {},
   "source": [
    "### 4. Modeling ###\n",
    "\n",
    "1. Setup pipeline and parameters for LDA\n",
    "2. Perform hyperparameter tuning for LDA\n",
    "3. Use best parameters of model for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6c02515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline and parameters for LDA\n",
    "pipeline_LDA = Pipeline([\n",
    "                ('bow', CountVectorizer()),\n",
    "                ('lda', LatentDirichletAllocation())]\n",
    "                )\n",
    "params_LDA = {\n",
    "            'bow__max_df': [0.2,0.3,0.4],\n",
    "            'bow__min_df': [10,15,20],\n",
    "            'bow__ngram_range': [(2,2), (2,3), (3,3)],\n",
    "            'lda__n_components': [3, 4, 5],\n",
    "            'lda__learning_decay' : [0.6, 0.7, 0.8],\n",
    "            'lda__max_iter': [10, 11, 12]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54185ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hyperparameter tuning\n",
    "def hyperparameter_tuning(pipeline, params, data, jobs = 4):\n",
    "    # Init Grid Search Class\n",
    "    model = GridSearchCV(estimator = pipeline, param_grid = params, n_jobs = jobs)\n",
    "    # Do the Grid Search\n",
    "    model.fit(data)\n",
    "    # Best Model\n",
    "    best_estimator = model.best_estimator_\n",
    "    # Model Parameters\n",
    "    print(\"Best Params: \", model.best_params_)\n",
    "    # Score\n",
    "    print(\"Best Score: \", model.best_score_)\n",
    "    return best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0297151c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'bow__max_df': 0.2, 'bow__min_df': 20, 'bow__ngram_range': (3, 3), 'lda__learning_decay': 0.8, 'lda__max_iter': 10, 'lda__n_components': 3}\n",
      "Best Score:  -158.36655327781645\n"
     ]
    }
   ],
   "source": [
    "# Get best LDA model\n",
    "best_lda_model = hyperparameter_tuning(pipeline_LDA, params_LDA, df['prepared_corpus'], jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a33cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vector model\n",
    "bow = best_lda_model.named_steps['bow']\n",
    "# Get vectorized data\n",
    "count_vectors = bow.transform(df['prepared_corpus'])\n",
    "# Get topic Model\n",
    "lda = best_lda_model.named_steps['lda']\n",
    "# Get lDA output\n",
    "lda_output = lda.transform(count_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd0872ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el102242402239764064757707798\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el102242402239764064757707798_data = {\"mdsDat\": {\"x\": [-0.35949827827117137, 0.23139637974770433, 0.128101898523467], \"y\": [-0.052857486005604436, -0.24951303511852424, 0.3023705211241286], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [22.52886786371066, 21.711122319280232, 55.76000981700911]}, \"tinfo\": {\"Term\": [\"dictate medquist job\", \"coronary artery disease\", \"acute renal failure\", \"alter mental status\", \"pain nausea vomit\", \"denies fever chill\", \"nausea vomit diarrhea\", \"denies chest pain\", \"chill night sweat\", \"fever chill night\", \"vomit diarrhea constipation\", \"cough shortness breath\", \"review system hpi\", \"sinus tenderness rhinorrhea\", \"tenderness rhinorrhea congestion\", \"dictate medquist job\", \"acute renal failure\", \"tenderness rhinorrhea congestion\", \"sinus tenderness rhinorrhea\", \"review system hpi\", \"cough shortness breath\", \"vomit diarrhea constipation\", \"fever chill night\", \"pain nausea vomit\", \"chill night sweat\", \"denies chest pain\", \"nausea vomit diarrhea\", \"alter mental status\", \"denies fever chill\", \"coronary artery disease\", \"coronary artery disease\", \"alter mental status\", \"pain nausea vomit\", \"review system hpi\", \"sinus tenderness rhinorrhea\", \"tenderness rhinorrhea congestion\", \"cough shortness breath\", \"vomit diarrhea constipation\", \"fever chill night\", \"chill night sweat\", \"denies chest pain\", \"nausea vomit diarrhea\", \"denies fever chill\", \"acute renal failure\", \"dictate medquist job\", \"denies fever chill\", \"nausea vomit diarrhea\", \"denies chest pain\", \"chill night sweat\", \"fever chill night\", \"vomit diarrhea constipation\", \"cough shortness breath\", \"review system hpi\", \"sinus tenderness rhinorrhea\", \"tenderness rhinorrhea congestion\", \"pain nausea vomit\", \"alter mental status\", \"acute renal failure\", \"coronary artery disease\", \"dictate medquist job\"], \"Freq\": [61.0, 47.0, 43.0, 37.0, 27.0, 41.0, 32.0, 29.0, 26.0, 24.0, 23.0, 23.0, 21.0, 19.0, 19.0, 60.487394644141155, 42.50597888963825, 0.3592228333840595, 0.35922283338019767, 0.3582677613293623, 0.3565940366577367, 0.3551803106808031, 0.35593808232137886, 0.37009409520854025, 0.3559996969792553, 0.37022672479293856, 0.3589898726393137, 0.3602217572537448, 0.37064372353575314, 0.36401312659444823, 46.74635458274658, 36.868259511656454, 16.070145376549586, 0.36584273118405786, 0.33151795695296604, 0.3315179569529718, 0.33481957867196643, 0.33037596193841207, 0.33140224993282774, 0.33157917651341534, 0.3708235412927987, 0.3409580156540537, 0.34043033703698766, 0.3389209976608945, 0.34621671141553567, 40.369491722662815, 31.98921309584821, 29.154412904177914, 25.475090752221348, 23.61085099393219, 22.680258251441735, 22.67481624737261, 20.779601844695392, 18.94668736452237, 18.946687364518954, 10.611056019221426, 0.31609215017864856, 0.353905553580655, 0.3136556116980734, 0.3110270492312186], \"Total\": [61.0, 47.0, 43.0, 37.0, 27.0, 41.0, 32.0, 29.0, 26.0, 24.0, 23.0, 23.0, 21.0, 19.0, 19.0, 61.14463840478791, 43.198805440879795, 19.637428154855986, 19.63742815485553, 21.503712337208814, 23.366229862702316, 23.36581452406095, 24.298191326186394, 27.05129549097955, 26.16266962571402, 29.89546317026365, 32.68916098414158, 37.54457341908885, 41.080565783235556, 47.4240233210391, 47.4240233210391, 37.54457341908885, 27.05129549097955, 21.503712337208814, 19.63742815485553, 19.637428154855986, 23.366229862702316, 23.36581452406095, 24.298191326186394, 26.16266962571402, 29.89546317026365, 32.68916098414158, 41.080565783235556, 43.198805440879795, 61.14463840478791, 41.080565783235556, 32.68916098414158, 29.89546317026365, 26.16266962571402, 24.298191326186394, 23.36581452406095, 23.366229862702316, 21.503712337208814, 19.63742815485553, 19.637428154855986, 27.05129549097955, 37.54457341908885, 43.198805440879795, 47.4240233210391, 61.14463840478791], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -0.5768, -0.9296, -5.7031, -5.7031, -5.7057, -5.7104, -5.7144, -5.7122, -5.6732, -5.7121, -5.6729, -5.7037, -5.7003, -5.6718, -5.6898, -0.7975, -1.0349, -1.8653, -5.6478, -5.7463, -5.7463, -5.7364, -5.7498, -5.7467, -5.7462, -5.6343, -5.7183, -5.7198, -5.7243, -5.703, -1.8874, -2.1201, -2.2129, -2.3478, -2.4238, -2.464, -2.4642, -2.5515, -2.6439, -2.6439, -3.2236, -6.7372, -6.6242, -6.745, -6.7534], \"loglift\": [15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4796, 1.4742, -2.5109, -2.5109, -2.6043, -2.6921, -2.696, -2.733, -2.8014, -2.8068, -2.901, -3.0211, -3.1562, -3.2177, -3.3793, 1.513, 1.5092, 1.0066, -2.5464, -2.5542, -2.5542, -2.7181, -2.7315, -2.7675, -2.8409, -2.8624, -3.0357, -3.2657, -3.3205, -3.6466, 0.5667, 0.5625, 0.559, 0.5575, 0.5554, 0.5543, 0.5541, 0.5499, 0.5483, 0.5483, -0.3517, -4.1931, -4.2204, -4.4345, -4.697]}, \"token.table\": {\"Topic\": [1, 2, 3, 2, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3], \"Freq\": [0.9953978949452231, 0.9854952828199676, 0.955559977542533, 0.9910588918580641, 0.9843265317146049, 0.9700468540940905, 0.9736964240235337, 0.9812798237973016, 0.9877278385792843, 0.9789177524477942, 0.5914689004574777, 0.4066348690645159, 0.9765755638231256, 0.9675401407033069, 0.9675401407032844, 0.9843440285942416], \"Term\": [\"acute renal failure\", \"alter mental status\", \"chill night sweat\", \"coronary artery disease\", \"cough shortness breath\", \"denies chest pain\", \"denies fever chill\", \"dictate medquist job\", \"fever chill night\", \"nausea vomit diarrhea\", \"pain nausea vomit\", \"pain nausea vomit\", \"review system hpi\", \"sinus tenderness rhinorrhea\", \"tenderness rhinorrhea congestion\", \"vomit diarrhea constipation\"]}, \"R\": 15, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el102242402239764064757707798\", ldavis_el102242402239764064757707798_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el102242402239764064757707798\", ldavis_el102242402239764064757707798_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el102242402239764064757707798\", ldavis_el102242402239764064757707798_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize topics\n",
    "# Create panel\n",
    "lda_display = pyLDAvis.sklearn.prepare(lda, count_vectors, bow, sort_topics=False)\n",
    "# Display panel\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83888dc",
   "metadata": {},
   "source": [
    "### 5.\tPredictions ###\n",
    "1. Identify topics (underlying factors) for existing documents (conditions)\n",
    "2. Identify top features (factors) in each topic\n",
    "3. Predict topic (underlying factors) for a new text (condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cebf4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document topc matrix\n",
    "def create_document_topic_matrix(topic_data, data):\n",
    "    # Create topic names\n",
    "    top_names = [\"Topic \" + str(c + 1) for c in range(lda.n_components)]\n",
    "    # Create doc names\n",
    "    doc_names = [\"Doc \" + str(rec) for rec in data['id'].values]\n",
    "    # Create data frame\n",
    "    df_doc_top = pd.DataFrame(np.round(topic_data, 4), columns = top_names, index = doc_names)\n",
    "    # Get main topic for each doc\n",
    "    main_topic = np.argmax(df_doc_top.values, axis=1) + 1\n",
    "    df_doc_top['Main Topic'] = main_topic\n",
    "    return df_doc_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e7b3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topc feature(word) matrix\n",
    "def create_topic_word_matrix(topic_model = lda, vector_model = bow):\n",
    "    # Create data frame\n",
    "    df_top_word = pd.DataFrame(topic_model.components_)\n",
    "    # Set column and index\n",
    "    df_top_word.columns = vector_model.get_feature_names()\n",
    "    df_top_word.index = [\"Topic \" + str(c + 1) for c in range(topic_model.n_components)]\n",
    "    return df_top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fdf58112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top n words for each topic\n",
    "def get_top_words(vector_model = bow, topic_model = lda, top_words = 20):\n",
    "    words = np.array(vector_model.get_feature_names())\n",
    "    topic_words = []\n",
    "    for topic_weights in topic_model.components_:\n",
    "        top_words_pos = (-topic_weights).argsort()[:top_words]\n",
    "        topic_words.append(words.take(top_words_pos))\n",
    "    return topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e6985bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict topic for gievn condition\n",
    "def predict_topic(list_of_conditions, topic_words, vector_model = bow, topic_model = lda):\n",
    "    # Create data frame from list of conditions\n",
    "    df_conditions = pd.DataFrame(list_of_conditions)\n",
    "    df_conditions.columns = ['Search Condition']\n",
    "    df_conditions.index = ['Query ' + str(i+1) for i in range(len(list_of_conditions))]\n",
    "    # Clean text\n",
    "    df_conditions = clean(df_conditions)\n",
    "    # Prepare query description\n",
    "    df_conditions = prepare_data(df_conditions, 'Search Condition', 'prepared_query')\n",
    "    # Vectorize input\n",
    "    vector_input = vector_model.transform(df_conditions['prepared_query'])\n",
    "    # LDA transform\n",
    "    topic_proba_scores = topic_model.transform(vector_input)\n",
    "    # Get topics\n",
    "    topics = []\n",
    "    for prob_scores in topic_proba_scores:\n",
    "        topic = topic_words.iloc[np.argmax(prob_scores), :].values.tolist()\n",
    "        topics.append(topic)\n",
    "    # Create data frame to return\n",
    "    search_conditions = df_conditions['prepared_query'].values\n",
    "    df_topics = pd.DataFrame(list(zip(search_conditions, topics)))\n",
    "    df_topics.columns = ['Search Condition','Topic Words']\n",
    "    df_topics.index = df_conditions.index\n",
    "    return df_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ef9d275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Main Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc 100035</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 100039</th>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 100187</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 100229</th>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.4963</td>\n",
       "      <td>0.4481</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 100564</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Topic 1  Topic 2  Topic 3  Main Topic\n",
       "Doc 100035   0.3333   0.3333   0.3333           1\n",
       "Doc 100039   0.1668   0.1669   0.6663           3\n",
       "Doc 100187   0.3333   0.3333   0.3333           1\n",
       "Doc 100229   0.0556   0.4963   0.4481           2\n",
       "Doc 100564   0.3333   0.3333   0.3333           1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get document topic data frame\n",
    "document_topic = create_document_topic_matrix(lda_output, df)\n",
    "# Check head\n",
    "document_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3658d3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Total Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Total Documents\n",
       "0      1              177\n",
       "1      3               70\n",
       "2      2               56"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check topic distribution\n",
    "topic_distribution = document_topic['Main Topic'].value_counts().reset_index()\n",
    "topic_distribution.columns = ['Topic', 'Total Documents']\n",
    "topic_distribution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f207d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acute renal failure</th>\n",
       "      <td>40.277297</td>\n",
       "      <td>0.343070</td>\n",
       "      <td>0.379633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alter mental status</th>\n",
       "      <td>0.341335</td>\n",
       "      <td>37.319595</td>\n",
       "      <td>0.339071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chill night sweat</th>\n",
       "      <td>0.337334</td>\n",
       "      <td>0.335638</td>\n",
       "      <td>27.327028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary artery disease</th>\n",
       "      <td>0.344927</td>\n",
       "      <td>47.318616</td>\n",
       "      <td>0.336457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cough shortness breath</th>\n",
       "      <td>0.337897</td>\n",
       "      <td>0.338918</td>\n",
       "      <td>24.323185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>denies chest pain</th>\n",
       "      <td>0.350815</td>\n",
       "      <td>0.375363</td>\n",
       "      <td>31.273822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>denies fever chill</th>\n",
       "      <td>0.351210</td>\n",
       "      <td>0.344598</td>\n",
       "      <td>43.304192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictate medquist job</th>\n",
       "      <td>57.315907</td>\n",
       "      <td>0.350455</td>\n",
       "      <td>0.333637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fever chill night</th>\n",
       "      <td>0.337275</td>\n",
       "      <td>0.335459</td>\n",
       "      <td>25.327265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nausea vomit diarrhea</th>\n",
       "      <td>0.340167</td>\n",
       "      <td>0.345132</td>\n",
       "      <td>34.314701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Topic 1    Topic 2    Topic 3\n",
       "acute renal failure      40.277297   0.343070   0.379633\n",
       "alter mental status       0.341335  37.319595   0.339071\n",
       "chill night sweat         0.337334   0.335638  27.327028\n",
       "coronary artery disease   0.344927  47.318616   0.336457\n",
       "cough shortness breath    0.337897   0.338918  24.323185\n",
       "denies chest pain         0.350815   0.375363  31.273822\n",
       "denies fever chill        0.351210   0.344598  43.304192\n",
       "dictate medquist job     57.315907   0.350455   0.333637\n",
       "fever chill night         0.337275   0.335459  25.327265\n",
       "nausea vomit diarrhea     0.340167   0.345132  34.314701"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check topic word matrix\n",
    "df_top_word = create_topic_word_matrix(lda, bow)\n",
    "df_top_word.T.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e5715f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "      <th>Word 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>dictate medquist job</td>\n",
       "      <td>acute renal failure</td>\n",
       "      <td>denies fever chill</td>\n",
       "      <td>denies chest pain</td>\n",
       "      <td>pain nausea vomit</td>\n",
       "      <td>coronary artery disease</td>\n",
       "      <td>alter mental status</td>\n",
       "      <td>tenderness rhinorrhea congestion</td>\n",
       "      <td>sinus tenderness rhinorrhea</td>\n",
       "      <td>nausea vomit diarrhea</td>\n",
       "      <td>review system hpi</td>\n",
       "      <td>cough shortness breath</td>\n",
       "      <td>chill night sweat</td>\n",
       "      <td>fever chill night</td>\n",
       "      <td>vomit diarrhea constipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>coronary artery disease</td>\n",
       "      <td>alter mental status</td>\n",
       "      <td>pain nausea vomit</td>\n",
       "      <td>denies chest pain</td>\n",
       "      <td>review system hpi</td>\n",
       "      <td>dictate medquist job</td>\n",
       "      <td>nausea vomit diarrhea</td>\n",
       "      <td>denies fever chill</td>\n",
       "      <td>acute renal failure</td>\n",
       "      <td>cough shortness breath</td>\n",
       "      <td>chill night sweat</td>\n",
       "      <td>tenderness rhinorrhea congestion</td>\n",
       "      <td>sinus tenderness rhinorrhea</td>\n",
       "      <td>fever chill night</td>\n",
       "      <td>vomit diarrhea constipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>denies fever chill</td>\n",
       "      <td>nausea vomit diarrhea</td>\n",
       "      <td>denies chest pain</td>\n",
       "      <td>chill night sweat</td>\n",
       "      <td>fever chill night</td>\n",
       "      <td>vomit diarrhea constipation</td>\n",
       "      <td>cough shortness breath</td>\n",
       "      <td>review system hpi</td>\n",
       "      <td>sinus tenderness rhinorrhea</td>\n",
       "      <td>tenderness rhinorrhea congestion</td>\n",
       "      <td>pain nausea vomit</td>\n",
       "      <td>acute renal failure</td>\n",
       "      <td>alter mental status</td>\n",
       "      <td>coronary artery disease</td>\n",
       "      <td>dictate medquist job</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Word 1                 Word 2              Word 3  \\\n",
       "Topic 1     dictate medquist job    acute renal failure  denies fever chill   \n",
       "Topic 2  coronary artery disease    alter mental status   pain nausea vomit   \n",
       "Topic 3       denies fever chill  nausea vomit diarrhea   denies chest pain   \n",
       "\n",
       "                    Word 4             Word 5                       Word 6  \\\n",
       "Topic 1  denies chest pain  pain nausea vomit      coronary artery disease   \n",
       "Topic 2  denies chest pain  review system hpi         dictate medquist job   \n",
       "Topic 3  chill night sweat  fever chill night  vomit diarrhea constipation   \n",
       "\n",
       "                         Word 7                            Word 8  \\\n",
       "Topic 1     alter mental status  tenderness rhinorrhea congestion   \n",
       "Topic 2   nausea vomit diarrhea                denies fever chill   \n",
       "Topic 3  cough shortness breath                 review system hpi   \n",
       "\n",
       "                              Word 9                           Word 10  \\\n",
       "Topic 1  sinus tenderness rhinorrhea             nausea vomit diarrhea   \n",
       "Topic 2          acute renal failure            cough shortness breath   \n",
       "Topic 3  sinus tenderness rhinorrhea  tenderness rhinorrhea congestion   \n",
       "\n",
       "                   Word 11                           Word 12  \\\n",
       "Topic 1  review system hpi            cough shortness breath   \n",
       "Topic 2  chill night sweat  tenderness rhinorrhea congestion   \n",
       "Topic 3  pain nausea vomit               acute renal failure   \n",
       "\n",
       "                             Word 13                  Word 14  \\\n",
       "Topic 1            chill night sweat        fever chill night   \n",
       "Topic 2  sinus tenderness rhinorrhea        fever chill night   \n",
       "Topic 3          alter mental status  coronary artery disease   \n",
       "\n",
       "                             Word 15  \n",
       "Topic 1  vomit diarrhea constipation  \n",
       "Topic 2  vomit diarrhea constipation  \n",
       "Topic 3         dictate medquist job  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top words\n",
    "topic_words = get_top_words(bow, lda, 10)        \n",
    "\n",
    "# Create topic words data frame\n",
    "df_top_words = pd.DataFrame(topic_words)\n",
    "df_top_words.columns = ['Word '+ str(i+1) for i in range(df_top_words.shape[1])]\n",
    "df_top_words.index = ['Topic '+ str(i+1) for i in range(df_top_words.shape[0])]\n",
    "\n",
    "# Check data\n",
    "df_top_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9eea1c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search Condition</th>\n",
       "      <th>Topic Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Query 1</th>\n",
       "      <td>congestive heart failure</td>\n",
       "      <td>[dictate medquist job, acute renal failure, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query 2</th>\n",
       "      <td>denies fever chill</td>\n",
       "      <td>[denies fever chill, nausea vomit diarrhea, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query 3</th>\n",
       "      <td>frequent vomit diarrhea nausea</td>\n",
       "      <td>[dictate medquist job, acute renal failure, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query 4</th>\n",
       "      <td>admission discharge service</td>\n",
       "      <td>[dictate medquist job, acute renal failure, de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Search Condition  \\\n",
       "Query 1        congestive heart failure   \n",
       "Query 2              denies fever chill   \n",
       "Query 3  frequent vomit diarrhea nausea   \n",
       "Query 4     admission discharge service   \n",
       "\n",
       "                                               Topic Words  \n",
       "Query 1  [dictate medquist job, acute renal failure, de...  \n",
       "Query 2  [denies fever chill, nausea vomit diarrhea, de...  \n",
       "Query 3  [dictate medquist job, acute renal failure, de...  \n",
       "Query 4  [dictate medquist job, acute renal failure, de...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define new search condtitions\n",
    "list_of_conditions = ['congestive heart failure', 'denies fever chills', 'frequent vomiting, diarrhea, and nausea', 'admission discharge service']\n",
    "# Get topics for new condistions\n",
    "df_condition_factors = predict_topic(list_of_conditions, df_top_words, bow, lda)\n",
    "# Display topics\n",
    "df_condition_factors.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4e7785",
   "metadata": {},
   "source": [
    "**Author:** Boris Kundu\n",
    "\n",
    "**Problem Statement:** Classify Iris types using GD with standard Momentum and Nesterov Momentum (PyTorch)\n",
    "\n",
    "**Dataset:** Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a35e5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55e8802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b756611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define input parameters\n",
    "n1 = len(iris.feature_names)  # input size\n",
    "k = len(iris.target_names)    # output size\n",
    "n2 = 5                        # hidden layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71022cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize weights and biases\n",
    "W1 = torch.randn(n1, n2, dtype=torch.double, requires_grad=True)\n",
    "b1 = torch.randn(n2, dtype=torch.double, requires_grad=True)\n",
    "W2 = torch.randn(n2, k, dtype=torch.double, requires_grad=True)\n",
    "b2 = torch.randn(k, dtype=torch.double, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ac896d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define input and output features\n",
    "X = torch.tensor(iris[\"data\"])\n",
    "target = torch.tensor(iris[\"target\"], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f30125f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize velocity for weights and biases\n",
    "vW1 = torch.zeros_like(W1)\n",
    "vb1 = torch.zeros_like(b1)\n",
    "vW2 = torch.zeros_like(W2)\n",
    "vb2 = torch.zeros_like(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "546d88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define system parameters\n",
    "alpha = 0.9 #Momentum\n",
    "eta = 0.01 #Learning rate\n",
    "epochs = 1000 #Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78ad6dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:1.4118387685376868 at Epoch:0\n",
      "Loss:0.8137970121631003 at Epoch:100\n",
      "Loss:0.6509584799482667 at Epoch:200\n",
      "Loss:0.5837409190877758 at Epoch:300\n",
      "Loss:0.5493200902891285 at Epoch:400\n",
      "Loss:0.5283783838507435 at Epoch:500\n",
      "Loss:0.5135961149868734 at Epoch:600\n",
      "Loss:0.5012734750808205 at Epoch:700\n",
      "Loss:0.4889235772845755 at Epoch:800\n",
      "Loss:0.4748257145459746 at Epoch:900\n"
     ]
    }
   ],
   "source": [
    "#Train model with GD using momentum\n",
    "for i in range(epochs):\n",
    "    o1 = X.matmul(W1) + b1\n",
    "    h = o1.sigmoid()\n",
    "    o2 = h.matmul(W2) + b2\n",
    "    L = F.cross_entropy(o2, target)\n",
    "    if (i%100 == 0):\n",
    "        print(f'Loss:{L.item()} at Epoch:{i}')\n",
    "    W1.grad = None\n",
    "    b1.grad = None\n",
    "    W2.grad = None\n",
    "    b2.grad = None\n",
    "    L.backward()\n",
    "    vb2 = alpha * vb2 - eta * b2.grad\n",
    "    b2.data = b2.data + vb2\n",
    "    vW2 = alpha * vW2 - eta * W2.grad\n",
    "    W2.data = W2.data + vW2\n",
    "    vb1 = alpha * vb1 - eta * b1.grad\n",
    "    b1.data = b1.data + vb1\n",
    "    vW1 = alpha * vW1 - eta * W1.grad\n",
    "    W1.data = W1.data + vW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b2b7185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "o1 = X.matmul(W1) + b1\n",
    "h = o1.sigmoid()\n",
    "o2 = h.matmul(W2) + b2\n",
    "ypred = o2.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f5694ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions using GD with momentum:\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1,\n",
      "        2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2])\n",
      "Matches using GD with momentum:140\n"
     ]
    }
   ],
   "source": [
    "#Display results\n",
    "print(f'Predictions using GD with momentum:\\n{ypred}')\n",
    "matches = torch.eq(ypred, target).int().sum()\n",
    "print(f'Matches using GD with momentum:{matches.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f5ced0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reinitialize weights and biases\n",
    "W1 = torch.randn(n1, n2, dtype=torch.double, requires_grad=True)\n",
    "b1 = torch.randn(n2, dtype=torch.double, requires_grad=True)\n",
    "W2 = torch.randn(n2, k, dtype=torch.double, requires_grad=True)\n",
    "b2 = torch.randn(k, dtype=torch.double, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fead85d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reinitialize velocity for weights and biases\n",
    "vW1 = torch.zeros_like(W1)\n",
    "vb1 = torch.zeros_like(b1)\n",
    "vW2 = torch.zeros_like(W2)\n",
    "vb2 = torch.zeros_like(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4fc54498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:1.334649500255506 at Epoch:0\n",
      "Loss:0.8107889651532572 at Epoch:100\n",
      "Loss:0.6382366482800941 at Epoch:200\n",
      "Loss:0.5378399577173137 at Epoch:300\n",
      "Loss:0.482266359523972 at Epoch:400\n",
      "Loss:0.4316132989969166 at Epoch:500\n",
      "Loss:0.3778874609395956 at Epoch:600\n",
      "Loss:0.32436055604498126 at Epoch:700\n",
      "Loss:0.27688551891405416 at Epoch:800\n",
      "Loss:0.2383225891867438 at Epoch:900\n"
     ]
    }
   ],
   "source": [
    "#Train model with GD using Nesterov momentum\n",
    "for i in range(epochs):\n",
    "    # Saving current\n",
    "    tW1 = W1.data  \n",
    "    tb1 = b1.data\n",
    "    tW2 = W2.data\n",
    "    tb2 = b2.data\n",
    "    # Move without gradient\n",
    "    W1.data = W1.data + alpha * vW1  \n",
    "    b1.data = b1.data + alpha * vb1\n",
    "    W2.data = W2.data + alpha * vW2\n",
    "    b2.data = b2.data + alpha * vb2\n",
    "    o1 = X.matmul(W1) + b1\n",
    "    h = o1.sigmoid()\n",
    "    o2 = h.matmul(W2) + b2\n",
    "    L = F.cross_entropy(o2, target) # not exactly the loss, but for gradient\n",
    "    if (i%100 == 0):\n",
    "        print(f'Loss:{L.item()} at Epoch:{i}')\n",
    "    W1.grad = None\n",
    "    b1.grad = None\n",
    "    W2.grad = None\n",
    "    b2.grad = None\n",
    "    L.backward()\n",
    "    vb2 = alpha * vb2 - eta * b2.grad\n",
    "    b2.data = tb2 + vb2\n",
    "    vW2 = alpha * vW2 - eta * W2.grad\n",
    "    W2.data = tW2 + vW2\n",
    "    vb1 = alpha * vb1 - eta * b1.grad\n",
    "    b1.data = tb1 + vb1\n",
    "    vW1 = alpha * vW1 - eta * W1.grad\n",
    "    W1.data = tW1 + vW1  # move from saved current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ba664bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions using new parameters\n",
    "o1 = X.matmul(W1) + b1\n",
    "h = o1.sigmoid()\n",
    "o2 = h.matmul(W2) + b2\n",
    "ypred = o2.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b98fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions using GD with Nesterov momentum:\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
      "        2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2])\n",
      "Matches using GD with Nesterov momentum:145\n"
     ]
    }
   ],
   "source": [
    "#Display results\n",
    "print(f'Predictions using GD with Nesterov momentum:\\n{ypred}')\n",
    "matches = torch.eq(ypred, target).int().sum()\n",
    "print(f'Matches using GD with Nesterov momentum:{matches.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1f5be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

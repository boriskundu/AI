{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c99a89",
   "metadata": {},
   "source": [
    "**Author:** Boris Kundu\n",
    "\n",
    "**Problem Statement:** Train and compare different optimizers.\n",
    "\n",
    "**Dataset:** Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89f02020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71f6be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d6f52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define input parameters\n",
    "n1 = len(iris.feature_names)  # input size\n",
    "k = len(iris.target_names)    # output size\n",
    "n2 = 5                        # hidden layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "126b3398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to define model\n",
    "class Model(nn.Module):\n",
    "    #Initialize\n",
    "    def __init__(self, datasize, hiddensize, outputsize):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(datasize, hiddensize)\n",
    "        self.layer2 = nn.Linear(hiddensize, outputsize)\n",
    "    #Feed forward\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.layer1(x))\n",
    "        return self.layer2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "470151d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define inputs and output\n",
    "X = torch.tensor(iris[\"data\"], dtype=torch.float)\n",
    "target = torch.tensor(iris[\"target\"], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c882d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define system parameters\n",
    "alpha = 0.9 #Momentum\n",
    "eta = 0.01 #Learning rate\n",
    "epochs = 1000 #Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e29f2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "model = Model(n1, n2, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b1b353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define different optimizers for comparison\n",
    "adaGrad = optim.Adagrad(model.parameters(), lr=eta)\n",
    "rmsProp = optim.RMSprop(model.parameters(), lr=eta)\n",
    "adam = optim.Adam(model.parameters(), lr=eta)\n",
    "adamW = optim.AdamW(model.parameters(), lr=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "258c72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "def predict(features,target_class,my_model,msg):\n",
    "    o2 = my_model(X)\n",
    "    ypred = o2.argmax(axis=1)\n",
    "    print(f'Predictions using {msg} are:\\n{ypred}')\n",
    "    matches = torch.eq(ypred, target).int().sum()\n",
    "    print(f'Matches using {msg} are:{matches.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1903b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model using optimizer\n",
    "def train(features,target_class,my_model,opt,msg):\n",
    "    for i in range(epochs):\n",
    "        o2 = my_model(features)\n",
    "        L = F.cross_entropy(o2, target_class)\n",
    "        if (i%100 == 0):\n",
    "            print(f'Loss:{L.item()} at Epoch:{i}')\n",
    "        opt.zero_grad()\n",
    "        L.backward()\n",
    "        opt.step()\n",
    "    #Predict\n",
    "    predict(features,target_class,my_model,msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b37e4897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:1.0684064626693726 at Epoch:0\n",
      "Loss:0.8466913104057312 at Epoch:100\n",
      "Loss:0.7325554490089417 at Epoch:200\n",
      "Loss:0.667316198348999 at Epoch:300\n",
      "Loss:0.6239688992500305 at Epoch:400\n",
      "Loss:0.5922978520393372 at Epoch:500\n",
      "Loss:0.5676078796386719 at Epoch:600\n",
      "Loss:0.5474175214767456 at Epoch:700\n",
      "Loss:0.5302877426147461 at Epoch:800\n",
      "Loss:0.5153290629386902 at Epoch:900\n",
      "Predictions using AdaGrad are:\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1,\n",
      "        2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2])\n",
      "Matches using AdaGrad are:145\n"
     ]
    }
   ],
   "source": [
    "#Train AdaGrad\n",
    "train(X,target,model,adaGrad,'AdaGrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4cf4ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.5019610524177551 at Epoch:0\n",
      "Loss:0.15814290940761566 at Epoch:100\n",
      "Loss:0.1010393351316452 at Epoch:200\n",
      "Loss:0.07857422530651093 at Epoch:300\n",
      "Loss:0.0671488493680954 at Epoch:400\n",
      "Loss:0.060310568660497665 at Epoch:500\n",
      "Loss:0.05609855800867081 at Epoch:600\n",
      "Loss:0.05328028276562691 at Epoch:700\n",
      "Loss:0.05130861699581146 at Epoch:800\n",
      "Loss:0.049885619431734085 at Epoch:900\n",
      "Predictions using RMSProp are:\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
      "        2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2])\n",
      "Matches using RMSProp are:146\n"
     ]
    }
   ],
   "source": [
    "#Train RMSProp\n",
    "train(X,target,model,rmsProp,'RMSProp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea505e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.048825278878211975 at Epoch:0\n",
      "Loss:0.04443224146962166 at Epoch:100\n",
      "Loss:0.042826540768146515 at Epoch:200\n",
      "Loss:0.04165118187665939 at Epoch:300\n",
      "Loss:0.040784478187561035 at Epoch:400\n",
      "Loss:0.04017601162195206 at Epoch:500\n",
      "Loss:0.039768002927303314 at Epoch:600\n",
      "Loss:0.039468422532081604 at Epoch:700\n",
      "Loss:0.03916464000940323 at Epoch:800\n",
      "Loss:0.038777656853199005 at Epoch:900\n",
      "Predictions using Adam are:\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2])\n",
      "Matches using Adam are:148\n"
     ]
    }
   ],
   "source": [
    "#Train Adam\n",
    "train(X,target,model,adam,'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f9702c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.03830048069357872 at Epoch:0\n",
      "Loss:0.03827093914151192 at Epoch:100\n",
      "Loss:0.03821292519569397 at Epoch:200\n",
      "Loss:0.038118284195661545 at Epoch:300\n",
      "Loss:0.03798876702785492 at Epoch:400\n",
      "Loss:0.03782551735639572 at Epoch:500\n",
      "Loss:0.037630002945661545 at Epoch:600\n",
      "Loss:0.03740396723151207 at Epoch:700\n",
      "Loss:0.03714967146515846 at Epoch:800\n",
      "Loss:0.036869149655103683 at Epoch:900\n",
      "Predictions using AdamW are:\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2])\n",
      "Matches using AdamW are:148\n"
     ]
    }
   ],
   "source": [
    "#Train AdamW\n",
    "train(X,target,model,adamW,'AdamW')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
